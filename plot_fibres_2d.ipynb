{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\nfrom pyvista import set_plot_theme\nset_plot_theme('document')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Example 1: full 2D example on real fibres data\n\nStart here: we present a real 2D example in detail, directly taking the data from the OrientationJ homepage: http://bigwww.epfl.ch/demo/orientation/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading libraries and data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib\nimport matplotlib.colors\nimport matplotlib.pyplot as plt\nimport numpy\nimport orientationpy\nimport tifffile\n\n# Load the greyscale image\nimage = tifffile.imread(\"../data/2D/image1_from_OrientationJ.tif\")\nprint(f\"The Y and X dimensions of the image: {image.shape}\")\n# Show image\nplt.imshow(image, cmap=\"Greys_r\")\nplt.suptitle(\"Original image\")\nplt.title(\"Courtesy of Carole Aemisegger, ZMB, University of Z\u00fcrich\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing Image Gradients\n This is one of the most key steps in the measurement of 2D orientations, the measurement of the local gradient for each pixel.\n For a 2D image, the result of this computation is two new images: the gradient in X and the gradient in Y.\n We have implemented several methods in our function, we believe that the gaussian method is the best for most cases.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for n, mode in enumerate([\"finite_difference\", \"gaussian\", \"splines\"]):\n    Gy, Gx = orientationpy.computeGradient(image, mode=mode)\n    plt.subplot(2, 3, n + 1)\n    plt.title(f\"{mode}-Gy\")\n    plt.imshow(Gy, cmap=\"coolwarm\", vmin=-64, vmax=64)\n\n    plt.subplot(2, 3, 3 + n + 1)\n    plt.title(f\"{mode}-Gx\")\n    plt.imshow(Gx, cmap=\"coolwarm\", vmin=-64, vmax=64)\nplt.show()\n\n# In the loop we've overwriting Gy and Gx, so at this point in the code they are the last (spines) gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute structure tensor\n Now we will now compute the Structure Tensor for each pixel https://en.wikipedia.org/wiki/Structure_tensor\n\n The result is in principle a 2 x 2 symmetric matrix for each pixel.\n We save only to top right side of the matrix meaning that the resulting array is 3 x 240 x 350\n The main setting to provide here is \"sigma\", which selects the spatial scale in pixels that we're interested in. Here it is set to 2 pixels\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "structureTensor = orientationpy.computeStructureTensor([Gy, Gx], sigma=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing Invariants\n The first invariant of the structure tensor is a measure for the local stength of the gradients.\n The second invariant is called directionality and measures how directed the structure tensors are.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "intensity = orientationpy.computeIntensity(structureTensor)\ndirectionality = orientationpy.computeStructureDirectionality(structureTensor)\n\n# directionality = np.log(directionality)\n#\n# print(directionality.flatten().max())\n# print(directionality.flatten().min())\n# print(numpy.sort(directionality.flatten())[-10:])\n# thresh_low = numpy.quantile(directionality.flatten(), 0.02)\n# print(\"thresh_low\", thresh_low)\n# thresh_high = numpy.quantile(directionality.flatten(), 0.98)\n# print(\"thresh_high\", thresh_high)\n#\n# plt.imshow(image, cmap=\"Greys_r\", vmin=0)\n# plt.imshow(directionality < thresh_low, cmap=\"Reds\", alpha=0.5)\n# plt.show()\n# plt.imshow(image, cmap=\"Greys_r\", vmin=0)\n# plt.imshow(directionality > thresh_high, cmap=\"Reds\", alpha=0.5)\n# plt.show()\n# exit()\n#\n# plt.figure()\n# plt.hist(directionality.flatten(), bins=20)\n# plt.show()\n# exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Intensities and Directionalities\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n\n# The intensity represents how strong the orientation signal is\nplt.subplot(1, 2, 1)\nplt.imshow(intensity / intensity.max(), vmin=0, vmax=1)\nplt.colorbar(shrink=0.7)\nplt.title(\"Intensity Normalised\")\n\n\nplt.subplot(1, 2, 2)\n# plt.imshow(directionality / directionality.max(), vmin=0, vmax=1)\nplt.imshow(directionality, norm=matplotlib.colors.LogNorm(vmin=10, vmax=1e8))\nplt.title(\"Directionaltiy Normalised\")\nplt.colorbar(shrink=0.7)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing Pixel-level orientations\n We will now pass the structureTensor to the computeOrientation function\n that will give us an angle in degrees from [90, -90] for each pixel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orientations = orientationpy.computeOrientation(structureTensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Overlay of orientations on image\n Overlay type 1 -- requires matlplotlib >= 3.1.3\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vmin, vmax = 10, 1e8\nnormalized_directionality = numpy.clip(directionality, vmin, vmax)\nnormalized_directionality = numpy.log(normalized_directionality)\nnormalized_directionality -= normalized_directionality.min()\nnormalized_directionality /= normalized_directionality.max()\nnormalized_directionality[image == 0] = 0\n\ntry:\n    plt.suptitle(\"Overlay with orientation\")\n    plt.title(\"Greyscale image with HSV orientations overlaid\\nwith transparency as log directionality\")\n    plt.imshow(image, cmap=\"Greys_r\", vmin=0)\n    plt.imshow(\n        orientations[\"theta\"],\n        cmap=\"hsv\",\n        alpha=normalized_directionality * 0.5,\n        vmin=-90,\n        vmax=90,\n    )\n\n    plt.colorbar(shrink=0.7)\n    plt.show()\nexcept:\n    print(\"Didn't manage to make the plot :(\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot HSV composition\n Alternative composition, with Hue, Saturation and Value\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imDisplayHSV = numpy.zeros((image.shape[0], image.shape[1], 3), dtype=\"f4\")\n# Hue is the orientation (nice circular mapping)\nimDisplayHSV[:, :, 0] = (orientations[\"theta\"] + 90) / 180\n# Saturation is directionality\nimDisplayHSV[:, :, 1] = normalized_directionality\n# Value is original image ;)\nimDisplayHSV[:, :, 2] = image / image.max()\n\nfig, ax = plt.subplots()\nfig.suptitle(\"Image-orientation composition\")\nax.set_title(\"Hue = Orientation\\nSaturation = log(Directionality)\\nV = image greylevels\")\nax.imshow(matplotlib.colors.hsv_to_rgb(imDisplayHSV))\n\ncmap = matplotlib.cm.hsv\nnorm = matplotlib.colors.Normalize(vmin=-90, vmax=90)\nfig.colorbar(\n    matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap),\n    ax=ax,\n    orientation=\"vertical\",\n    label=\"degrees from horizontal\",\n    shrink=0.7,\n)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing boxed orientations\n Starting again from the gradients, the Structure Tensor can also be computed\n in boxes.\n Here we split the image up into regular boxes of 7 pixels a side\n and average the structure tensor in each one.\n The result is then plotted in the centre of each box\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "boxSizePixels = 7\nstructureTensorBoxes = orientationpy.computeStructureTensorBoxes(\n    [Gy, Gx],\n    [boxSizePixels, boxSizePixels],\n)\nintensityBoxes = orientationpy.computeIntensity(structureTensorBoxes)\n\n# The structure tensor in boxes is passed to the same function to compute\n# The orientation\norientationsBoxes = orientationpy.computeOrientation(\n    structureTensorBoxes,\n    mode=\"fiber\",\n)\n\n# We normalise the intensity, to be able to hide arrows in the subsequent quiver plot\nintensityBoxes /= intensityBoxes.max()\n\n# Compute box centres\nboxCentresY = numpy.arange(orientationsBoxes[\"theta\"].shape[0]) * boxSizePixels + boxSizePixels // 2\nboxCentresX = numpy.arange(orientationsBoxes[\"theta\"].shape[1]) * boxSizePixels + boxSizePixels // 2\n\n# Compute X and Y components of the vector\nboxVectorsYX = orientationpy.anglesToVectors(orientationsBoxes)\n\n# Vectors with low intensity reset\nboxVectorsYX[:, intensityBoxes < 0.05] = 0.0\n\nplt.title(\"Local orientation vector in boxes\")\nplt.imshow(image, cmap=\"Greys_r\", vmin=0)\n\n# Warning, matplotlib is XY convention, not YX!\nplt.quiver(\n    boxCentresX,\n    boxCentresY,\n    boxVectorsYX[1],\n    boxVectorsYX[0],\n    angles=\"xy\",\n    scale_units=\"xy\",\n    # scale=intensityBoxes.ravel(),\n    color=\"r\",\n    headwidth=0,\n    headlength=0,\n    headaxislength=1,\n)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}